{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00471/Data_for_UCI_named.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab     stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     0\n",
       "tau2     0\n",
       "tau3     0\n",
       "tau4     0\n",
       "p1       0\n",
       "p2       0\n",
       "p3       0\n",
       "p4       0\n",
       "g1       0\n",
       "g2       0\n",
       "g3       0\n",
       "g4       0\n",
       "stab     0\n",
       "stabf    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following instruction from dataset description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop stab and stabf\n",
    "X = df.drop(columns = ['stab','stabf'])\n",
    "y = df['stabf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unstable    6380\n",
       "stable      3620\n",
       "Name: stabf, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y, random_state = 1, test_size=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unstable    1288\n",
       "stable       712\n",
       "Name: stabf, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.367327</td>\n",
       "      <td>-0.986042</td>\n",
       "      <td>0.650447</td>\n",
       "      <td>1.547527</td>\n",
       "      <td>-0.291490</td>\n",
       "      <td>0.061535</td>\n",
       "      <td>1.293862</td>\n",
       "      <td>-0.845074</td>\n",
       "      <td>0.160918</td>\n",
       "      <td>0.339859</td>\n",
       "      <td>0.585568</td>\n",
       "      <td>0.492239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.064659</td>\n",
       "      <td>0.089437</td>\n",
       "      <td>1.035079</td>\n",
       "      <td>-1.641494</td>\n",
       "      <td>0.619865</td>\n",
       "      <td>-0.067235</td>\n",
       "      <td>-1.502925</td>\n",
       "      <td>0.486613</td>\n",
       "      <td>-0.293143</td>\n",
       "      <td>-1.558488</td>\n",
       "      <td>1.429649</td>\n",
       "      <td>-1.443521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.467850</td>\n",
       "      <td>1.298418</td>\n",
       "      <td>-0.502536</td>\n",
       "      <td>1.166046</td>\n",
       "      <td>-0.180521</td>\n",
       "      <td>0.490603</td>\n",
       "      <td>0.682560</td>\n",
       "      <td>-0.855302</td>\n",
       "      <td>1.399350</td>\n",
       "      <td>1.451534</td>\n",
       "      <td>-1.045743</td>\n",
       "      <td>0.492489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.820081</td>\n",
       "      <td>0.529920</td>\n",
       "      <td>1.299657</td>\n",
       "      <td>-1.141975</td>\n",
       "      <td>-0.812854</td>\n",
       "      <td>-0.763632</td>\n",
       "      <td>1.521579</td>\n",
       "      <td>0.658780</td>\n",
       "      <td>-0.958319</td>\n",
       "      <td>1.361958</td>\n",
       "      <td>1.604140</td>\n",
       "      <td>0.275303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.665424</td>\n",
       "      <td>-1.425627</td>\n",
       "      <td>0.312300</td>\n",
       "      <td>0.919137</td>\n",
       "      <td>-1.614296</td>\n",
       "      <td>0.760315</td>\n",
       "      <td>1.422019</td>\n",
       "      <td>0.639243</td>\n",
       "      <td>1.676895</td>\n",
       "      <td>0.695660</td>\n",
       "      <td>1.137504</td>\n",
       "      <td>-1.312575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  0.367327 -0.986042  0.650447  1.547527 -0.291490  0.061535  1.293862   \n",
       "1 -0.064659  0.089437  1.035079 -1.641494  0.619865 -0.067235 -1.502925   \n",
       "2 -1.467850  1.298418 -0.502536  1.166046 -0.180521  0.490603  0.682560   \n",
       "3  0.820081  0.529920  1.299657 -1.141975 -0.812854 -0.763632  1.521579   \n",
       "4  0.665424 -1.425627  0.312300  0.919137 -1.614296  0.760315  1.422019   \n",
       "\n",
       "         p4        g1        g2        g3        g4  \n",
       "0 -0.845074  0.160918  0.339859  0.585568  0.492239  \n",
       "1  0.486613 -0.293143 -1.558488  1.429649 -1.443521  \n",
       "2 -0.855302  1.399350  1.451534 -1.045743  0.492489  \n",
       "3  0.658780 -0.958319  1.361958  1.604140  0.275303  \n",
       "4  0.639243  1.676895  0.695660  1.137504 -1.312575  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_x_train = scaler.fit_transform(x_train)\n",
    "scaled_x_train = pd.DataFrame(scaled_x_train,columns = x_train.columns)\n",
    "scaled_x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x_test = scaler.transform(x_test)\n",
    "scaled_x_test = pd.DataFrame(scaled_x_test, columns = x_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state =1)\n",
    "rfc.fit(scaled_x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_forest = rfc.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.929\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test,pred_forest)\n",
    "print(f\"Accuracy: {round(accuracy,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(random_state=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etc = ExtraTreesClassifier(random_state = 1)\n",
    "etc.fit(scaled_x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tree = etc.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.928\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test,pred_tree)\n",
    "print(f\"Accuracy: {round(accuracy,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='logloss',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "              num_parallel_tree=1, random_state=1, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgbc = XGBClassifier(random_state=1, eval_metric = \"logloss\")\n",
    "xgbc.fit(scaled_x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb = xgbc.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9455\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, pred_xgb)\n",
    "print(f\"Accuracy: {round(accuracy,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(random_state=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier(random_state=1)\n",
    "lgbm.fit(scaled_x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lgmb = lgbm.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9395\n"
     ]
    }
   ],
   "source": [
    "accuracy_ = accuracy_score(y_test,pred_lgmb)\n",
    "print(f\"Accuracy: {round(accuracy_,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50,100,300,500,1000] \n",
    "min_samples_split = [2,3,5,7,9] \n",
    "min_samples_leaf = [1,2,4,6,8] \n",
    "max_features = ['auto','sqrt','log2',None] \n",
    "hyperparameter_grid = {'n_estimators':n_estimators,\n",
    "                       'min_samples_leaf':min_samples_leaf,\n",
    "                       'min_samples_split':min_samples_split,\n",
    "                       'max_features':max_features}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Cross Validation Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_search = RandomizedSearchCV(estimator = etc,param_distributions=hyperparameter_grid,random_state=1)\n",
    "ran_search = ran_search.fit(scaled_x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 8,\n",
       " 'max_features': None}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New classifier using Extra tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classifier = ExtraTreesClassifier(random_state=1,n_estimators = 1000,\n",
    "                                       min_samples_leaf= 8,max_features=None,\n",
    "                                       min_samples_split=2)\n",
    "n_classifier.fit(scaled_x_train,y_train)\n",
    "new_pred = n_classifier.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.927\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test,new_pred)\n",
    "print(f\"Accuracy: {round(accuracy,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13723975, 0.1405075 , 0.13468029, 0.13541676, 0.00368342,\n",
       "       0.00533686, 0.00542927, 0.00496249, 0.10256244, 0.10757765,\n",
       "       0.11306268, 0.10954089])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = ran_search.best_estimator_.feature_importances_\n",
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_imp_feat = imp.max()\n",
    "least_imp_feat = imp.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "most = X.columns[imp == most_imp_feat]\n",
    "least = X.columns[imp == least_imp_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most important features is tau2\n",
      "least important features is p1\n"
     ]
    }
   ],
   "source": [
    "print(f\"most important features is {most[0]}\")\n",
    "print(f\"least important features is {least[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.14050750384993677, 'tau2'),\n",
       " (0.13723974766109256, 'tau1'),\n",
       " (0.1354167630909727, 'tau4'),\n",
       " (0.13468028520386593, 'tau3'),\n",
       " (0.11306267999167334, 'g3'),\n",
       " (0.10954089174337298, 'g4'),\n",
       " (0.10757764577478764, 'g2'),\n",
       " (0.10256244080927947, 'g1'),\n",
       " (0.005429268421191957, 'p3'),\n",
       " (0.005336864710946151, 'p2'),\n",
       " (0.004962486591192238, 'p4'),\n",
       " (0.003683422151688322, 'p1')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(imp,X),reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You are working on a spam classifi cation system using regularized logisticregression. “Spam” is a positive class (y = 1) and “not spam” is the negative class (y =0). You have trained your classifi er and there are n = 2000 examples in the test set.The confusion matrix of predicted class vs. actual class is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2375\n",
      "Precision: 0.19346049046321526\n",
      "Recall: 0.8875\n",
      "F1 Score: 0.3176733780760626\n"
     ]
    }
   ],
   "source": [
    "TP = 355\n",
    "TN = 120\n",
    "FP = 1480\n",
    "FN = 45\n",
    "total = TP+TN+FP+FN\n",
    "\n",
    "accuracy = (TP+TN)/total\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "precision = TP / (TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "recall = TP / (TP + FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which method can we use to best fi t a data in Logistic Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "### maximum likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we use weak learners in boosting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To prevent overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A data scientist is evaluating different binary classifi cation models. A false positiveresult is 5 times more expensive (from a business perspective) than a false negativeresult. The models should be evaluated based on the following criteria:\n",
    "    1) Must have a recall rate of at least 80%\n",
    "    2) Must have a false positive rate of 10% or less\n",
    "    3) Must minimize business costs\n",
    "### After creating each binary classifi cation model, the data scientist generates thecorresponding confusion matrix. Which confusion matrix represents the modelthat satisfi es the requirements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall A = 82.0, FPR A = 2.0, Cost A = 28 \n",
      "Recall B = 90.0, FPR B = 4.0, Cost B = 30 \n",
      "Recall C = 79.0, FPR C = 1.0, Cost C = 26 \n",
      "Recall D = 78.0, FPR D = 9.0, Cost D = 67 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>78.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recall  FPR  Cost\n",
       "A    82.0  2.0    28\n",
       "B    90.0  4.0    30\n",
       "C    79.0  1.0    26\n",
       "D    78.0  9.0    67"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using a trial and error method from the options\n",
    "\n",
    "options = {\"A\": {\"tN\": 98, \"fP\": 2, \"fN\":18, \"tP\":82}, \n",
    "           \"B\": {\"tN\": 96, \"fP\": 4, \"fN\":10, \"tP\":90},\n",
    "            \"C\": {\"tN\": 99, \"fP\": 1, \"fN\":21, \"tP\": 79},\n",
    "            \"D\": {\"tN\": 91, \"fP\": 9, \"fN\":22, \"tP\":78}\n",
    "          }\n",
    "rec = []\n",
    "fp = []\n",
    "cs = []\n",
    "## finding recall,fpr,cost given the values from option\n",
    "for option,val in options.items():\n",
    "    v = val\n",
    "    recall = v[\"tP\"] / (v[\"tP\"] + v[\"fN\"])\n",
    "    fpr = v[\"fP\"] / (v[\"fP\"] + v[\"tN\"])\n",
    "    cost = 5 * v[\"fP\"] + v[\"fN\"]\n",
    "    rec.append(recall*100)\n",
    "    fp.append(round(fpr*100,2))\n",
    "    cs.append(cost)\n",
    "    print(f\"Recall {option} = {recall*100}, FPR {option} = {round(fpr*100,2)}, Cost {option} = {cost} \")\n",
    "\n",
    "df = pd.DataFrame({\"Recall\": rec, \"FPR\": fp, \"Cost\": cs}, index = [\"A\",\"B\",\"C\",\"D\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recall  FPR  Cost\n",
       "A    82.0  2.0    28\n",
       "B    90.0  4.0    30"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Recall\"]> 80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You are building a classifi er and the accuracy is poor on both the training and testsets. Which would you use to try to improve the performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which of the following is not an Ensemble model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A classifier predicts if insurance claims are fraudulent or not. The cost of paying afraudulent claim is higher than the cost of investigating a claim that is suspected tobe fraudulent. Which metric should we use to evaluate this classifi er?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ROC curve above was generated from a classifi cation algorithm. What can wesay about this classifi er?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The model has no discrimination capacity to differentiate between the positive and thenegative class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A random forest classifi er was used to classify handwritten digits 0-9 into thenumbers they were intended to represent. The confusion matrix below wasgenerated from the results. Based on the matrix, which number was predicted withthe least accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A medical company is building a model to predict the occurrence of thyroid cancer The training data contains 900 negative instances (people who dont have cancer)and 100 positive instances. The resulting model has 90% accuracy, but extremelypoor recall. What steps can be used to improve the model's performance? (SELECTTWO OPTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Collect more data for the positive case\n",
    "### Generate synthetic samples/data using SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You are developing a machine learning classifi cation algorithm that categorizeshandwritten digits 0-9 into the numbers they represent. How should you pre-process the label data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the entropy of the target variable if its actual values are given as: [1,0,1,1,0,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### formula: -(Summation [p(x) * log p(x)])\n",
    "### - 3/7 log(3/7) - 4/7 log(4/7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which of this is not a good metric for evaluating classifi cation algorithms for datawith imbalanced class problems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Accuracy is not the best metric to use when evaluating imbalanced datasets as it can be misleading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the accuracy on the test set using the random forest classifi er? In 4 decimalplaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 0.9295"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the accuracy on the test set using the xgboost classifi er? In 4 decimalplaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 0.9195"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the accuracy on the test set using the LGBM classifi er? In 4 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 0.9375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the ExtraTreesClassifi er as your estimator with cv=5, n_iter=10, scoring ='accuracy', n_jobs = -1, verbose = 1 and random_state = 1. What are the besthyperparameters from the randomized search CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### N_estimators = 1000 , min_samples_split = 2 , min_samples_leaf = 8, max_features = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a new ExtraTreesClassifi er Model with the new Hyperparameters from theRandomizedSearchCV (with random_state = 1). Is the accuracy of the new optimalmodel higher or lower than the initial ExtraTreesClassifi er model with nohyperparameter tuning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What other hyperparameter optimization methods can you try apart from RandomSearch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### All of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the feature importance using the optimal ExtraTreesClassifi er model. Whichfeatures are the most and least important respectively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tau2, p1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
