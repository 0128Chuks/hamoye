{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nimport seaborn as sns\nfrom skimage import io\nfrom tqdm import tqdm\nimport cv2\nimport gc\n%matplotlib inline\n","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:00:37.206125Z","iopub.execute_input":"2021-10-19T18:00:37.206530Z","iopub.status.idle":"2021-10-19T18:00:42.307408Z","shell.execute_reply.started":"2021-10-19T18:00:37.206419Z","shell.execute_reply":"2021-10-19T18:00:42.306654Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/planet-understanding-the-amazon-from-space/train_v2.csv/train_v2.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:00:42.309141Z","iopub.execute_input":"2021-10-19T18:00:42.309375Z","iopub.status.idle":"2021-10-19T18:00:42.376220Z","shell.execute_reply.started":"2021-10-19T18:00:42.309345Z","shell.execute_reply":"2021-10-19T18:00:42.375499Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Build list with unique labels\nlabel_list = []\nfor tag_str in train_df.tags.values:\n    labels = tag_str.split(' ')\n    for label in labels:\n        if label not in label_list:\n            label_list.append(label)\nlabel_list","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:00:42.377646Z","iopub.execute_input":"2021-10-19T18:00:42.377885Z","iopub.status.idle":"2021-10-19T18:00:42.425020Z","shell.execute_reply.started":"2021-10-19T18:00:42.377852Z","shell.execute_reply":"2021-10-19T18:00:42.424257Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Add onehot features for every label\nfor label in label_list:\n    train_df[label] = train_df['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n# Display head\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:00:42.426511Z","iopub.execute_input":"2021-10-19T18:00:42.426787Z","iopub.status.idle":"2021-10-19T18:00:42.971862Z","shell.execute_reply.started":"2021-10-19T18:00:42.426754Z","shell.execute_reply":"2021-10-19T18:00:42.971061Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Histogram of label instances\ntrain_df[label_list].sum().sort_values().plot.bar()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:00:42.974363Z","iopub.execute_input":"2021-10-19T18:00:42.974633Z","iopub.status.idle":"2021-10-19T18:00:43.293267Z","shell.execute_reply.started":"2021-10-19T18:00:42.974583Z","shell.execute_reply":"2021-10-19T18:00:43.292486Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# creating a function that generates a concurrent matrix \n# (a matrix that contains the number of overlaps of pairs of tags)\ndef make_cooccurence_matrix(labels):\n    numeric_df = train_df[labels]; \n    c_matrix = numeric_df.T.dot(numeric_df)\n#     mask = np.triu(np.ones((len(labels), len(labels))))\n    sns.heatmap(c_matrix, cmap=sns.cm.rocket_r)\n\n#     sns.heatmap(c_matrix)\n    return c_matrix","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:00:43.294462Z","iopub.execute_input":"2021-10-19T18:00:43.294997Z","iopub.status.idle":"2021-10-19T18:00:43.300498Z","shell.execute_reply.started":"2021-10-19T18:00:43.294962Z","shell.execute_reply":"2021-10-19T18:00:43.299764Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Compute the co-ocurrence matrix for all labels\nmake_cooccurence_matrix(label_list)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:00:43.302052Z","iopub.execute_input":"2021-10-19T18:00:43.302360Z","iopub.status.idle":"2021-10-19T18:00:43.919161Z","shell.execute_reply.started":"2021-10-19T18:00:43.302325Z","shell.execute_reply":"2021-10-19T18:00:43.918343Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"#### Remark: 'primary' and 'clear seems to have the most overlap amongst all labels","metadata":{}},{"cell_type":"code","source":"# classifying the tags into the three categories of : \n# ['atmospheric condition(weather_labels)', 'common land cover(land_labels)' and  'rare land cover(rare_labels)']\n\nweather_labels = ['clear', 'partly_cloudy','cloudy', 'haze']\nland_labels = ['primary', 'water', 'habitation', 'agriculture', 'road', 'cultivation', 'bare_ground']\nrare_labels = [tag for tag in label_list if (tag not in weather_labels) and (tag not in land_labels)]","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:00:43.920742Z","iopub.execute_input":"2021-10-19T18:00:43.920992Z","iopub.status.idle":"2021-10-19T18:00:43.926439Z","shell.execute_reply.started":"2021-10-19T18:00:43.920959Z","shell.execute_reply":"2021-10-19T18:00:43.925674Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Compute the co-ocurrence matrix for weather-labels\nmake_cooccurence_matrix(weather_labels)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:00:43.927655Z","iopub.execute_input":"2021-10-19T18:00:43.928154Z","iopub.status.idle":"2021-10-19T18:00:44.180028Z","shell.execute_reply.started":"2021-10-19T18:00:43.928022Z","shell.execute_reply":"2021-10-19T18:00:44.179354Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"\n#### Remark: No overlap in atmospheric condition","metadata":{}},{"cell_type":"code","source":"# Compute the co-ocurrence matrix for land-labels\nmake_cooccurence_matrix(land_labels)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:00:44.181238Z","iopub.execute_input":"2021-10-19T18:00:44.181647Z","iopub.status.idle":"2021-10-19T18:00:44.489512Z","shell.execute_reply.started":"2021-10-19T18:00:44.181587Z","shell.execute_reply":"2021-10-19T18:00:44.488857Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"#### Remark: 'primary' and 'agriculture' seems to have the most overlap amongst common-land-cover","metadata":{}},{"cell_type":"code","source":"# Compute the co-ocurrence matrix for rare-labels\nmake_cooccurence_matrix(rare_labels)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:00:44.490740Z","iopub.execute_input":"2021-10-19T18:00:44.491121Z","iopub.status.idle":"2021-10-19T18:00:44.796333Z","shell.execute_reply.started":"2021-10-19T18:00:44.491082Z","shell.execute_reply":"2021-10-19T18:00:44.795658Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"#### Remark: 'selective_logging' and 'blooming' seems to have the most overlap amongst rare-land-cover","metadata":{}},{"cell_type":"markdown","source":"## Inspect Images","metadata":{}},{"cell_type":"code","source":"# adding '.jpg' extension to 'image_name'\ntrain_df['image_name'] = train_df['image_name'].apply(lambda x: '{}.jpg'.format(x)) \ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:00:44.797382Z","iopub.execute_input":"2021-10-19T18:00:44.797751Z","iopub.status.idle":"2021-10-19T18:00:44.834048Z","shell.execute_reply.started":"2021-10-19T18:00:44.797714Z","shell.execute_reply":"2021-10-19T18:00:44.833316Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import tarfile\ndef extract(tar_file, path):\n    opened_tar = tarfile.open(tar_file)\n     \n    if tarfile.is_tarfile(tar_file):\n        opened_tar.extractall(path)\n    else:\n        print(\"The tar file you entered is not a tar file\")","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:00:44.835240Z","iopub.execute_input":"2021-10-19T18:00:44.835776Z","iopub.status.idle":"2021-10-19T18:00:44.841653Z","shell.execute_reply.started":"2021-10-19T18:00:44.835738Z","shell.execute_reply":"2021-10-19T18:00:44.840773Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# let's view a sample image say 'train_10.jpg' \nimage_number = 5\nsample_img = io.imread('../input/train-jpg/train-jpg/train_{}.jpg'.format(image_number))\nr, g, b = sample_img[:, :, 0], sample_img[:, :, 1], sample_img[:, :, 2]\nsample_img.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:00:44.845595Z","iopub.execute_input":"2021-10-19T18:00:44.846092Z","iopub.status.idle":"2021-10-19T18:00:44.863649Z","shell.execute_reply.started":"2021-10-19T18:00:44.846056Z","shell.execute_reply":"2021-10-19T18:00:44.862929Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# displaying the red, green and blue channels seperately\nfig = plt.figure()\nfig.set_size_inches(12, 4)\nfor ind, (img, channel) in enumerate(((r, 'r'), (g, 'g'), (b, 'b'))):\n    a = fig.add_subplot(1, 4, ind+1)\n    a.set_title(channel)\n    plt.imshow(img)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:00:44.864986Z","iopub.execute_input":"2021-10-19T18:00:44.865469Z","iopub.status.idle":"2021-10-19T18:00:45.310407Z","shell.execute_reply.started":"2021-10-19T18:00:44.865435Z","shell.execute_reply":"2021-10-19T18:00:45.309668Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"plt.imshow(sample_img) # displaying all channels at once","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:00:45.311369Z","iopub.execute_input":"2021-10-19T18:00:45.311616Z","iopub.status.idle":"2021-10-19T18:00:45.556370Z","shell.execute_reply.started":"2021-10-19T18:00:45.311562Z","shell.execute_reply":"2021-10-19T18:00:45.555735Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Processing Images","metadata":{}},{"cell_type":"code","source":"y_col = list(train_df.columns[2:]) # storing the tags column names as a variable\n\n# initializing an image generator with some data augumentation\nimage_gen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=45, horizontal_flip=True, \\\n                                            vertical_flip=True, zoom_range=0.2)\n\n# loading images from dataframe\nX = image_gen.flow_from_dataframe(dataframe=train_df, \\\n        directory='../input/train-jpg/train-jpg/', x_col='image_name', y_col=y_col, \\\n       target_size=(128, 128), class_mode='raw', seed=1, batch_size=128)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:00:45.557544Z","iopub.execute_input":"2021-10-19T18:00:45.557931Z","iopub.status.idle":"2021-10-19T18:01:16.586098Z","shell.execute_reply.started":"2021-10-19T18:00:45.557896Z","shell.execute_reply":"2021-10-19T18:01:16.584340Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# X is an iterable, It contains 317 batches, each batch contains 128 images and labels because \n#40479 / 128 is 316 remainder 31 each image is of shape (128, 128, 3), each label is of shape (17, )\n\n# let's abitrarily view an image\nx109 = X[0][0][109] # first batch, images, 109th image\ny109 = X[0][1][109] # first batch, labels, 109th label\nprint(\"each image's shape is {}\".format(x109.shape))\nprint(\"each label's shape is {}\".format(y109.shape))\nprint('we have {} batches'.format(len(X)))\nprint('each batch has {} images/labels'.format(X[0][0].shape[0]))\nprint('40479/128 is {:.2F}, so the last batch will have {} images/labels'.format(40479/128, X[316][0].shape[0]))","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:01:16.588806Z","iopub.execute_input":"2021-10-19T18:01:16.589103Z","iopub.status.idle":"2021-10-19T18:01:19.198443Z","shell.execute_reply.started":"2021-10-19T18:01:16.589066Z","shell.execute_reply":"2021-10-19T18:01:19.197637Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"plt.imshow(x109/255) # divided by 255 so the image can be displayed","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:01:19.199759Z","iopub.execute_input":"2021-10-19T18:01:19.200615Z","iopub.status.idle":"2021-10-19T18:01:19.448720Z","shell.execute_reply.started":"2021-10-19T18:01:19.200553Z","shell.execute_reply":"2021-10-19T18:01:19.448070Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# importing useful deep learning libraries\n\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:01:19.449751Z","iopub.execute_input":"2021-10-19T18:01:19.450101Z","iopub.status.idle":"2021-10-19T18:01:19.458666Z","shell.execute_reply.started":"2021-10-19T18:01:19.450067Z","shell.execute_reply":"2021-10-19T18:01:19.457825Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# defining a function to calculate fbeta score\n\ndef fbeta(ytrue, ypred, beta=2, threshold=0.2, epsilon=1e-7):\n    # threshold is set to 0.2 to maximize recall since f2 score is recall biased\n    # epsilon is set to 1e-7 to avoide Nan values due to zero division\n    \n    beta_squarred = float(beta)**2\n    \n    ytrue = tf.cast(ytrue, tf.float32) # casts ytrue as a float\n    # convert ypred to bool, then to float\n    ypred = tf.cast(tf.greater(tf.cast(ypred, tf.float32), tf.constant(threshold)), tf.float32) \n    \n    tp = tf.reduce_sum(tf.cast(tf.equal((2.0*ytrue + ypred), tf.constant(3.0)), tf.float32), axis=1) \n    fp = tf.reduce_sum(tf.cast(tf.equal((2.0*ytrue + ypred), tf.constant(1.0)), tf.float32), axis=1)\n    fn = tf.reduce_sum(tf.cast(tf.equal((2.0*ytrue + ypred), tf.constant(2.0)), tf.float32), axis=1)\n\n    precision = tp / (tp+fp)\n    recall = tp / (tp+fn)\n    fb = (beta_squarred+1) * precision * recall / (precision*beta_squarred + recall + epsilon)\n  \n    return fb","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:01:19.459853Z","iopub.execute_input":"2021-10-19T18:01:19.460404Z","iopub.status.idle":"2021-10-19T18:01:19.472925Z","shell.execute_reply.started":"2021-10-19T18:01:19.460370Z","shell.execute_reply":"2021-10-19T18:01:19.472049Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# creating a function to calculate multi-label accuracy \n\ndef multi_label_acc(ytrue, ypred, threshold=0.2, epsilon=1e-7):\n    # threshold is set to 0.2 to maximize recall since f2 score is recall biased\n    # epsilon is set to 1e-7 to avoide Nan values due to zero division\n    \n    ytrue = tf.cast(ytrue, tf.float32) # casts ytrue as a float\n    # convert ypred to bool, then to float\n    ypred = tf.cast(tf.greater(tf.cast(ypred, tf.float32), tf.constant(threshold)), tf.float32) \n    \n    tp = tf.reduce_sum(tf.cast(tf.equal((2.0*ytrue + ypred), tf.constant(3.0)), tf.float32), axis=1) \n    fp = tf.reduce_sum(tf.cast(tf.equal((2.0*ytrue + ypred), tf.constant(1.0)), tf.float32), axis=1)\n    fn = tf.reduce_sum(tf.cast(tf.equal((2.0*ytrue + ypred), tf.constant(2.0)), tf.float32), axis=1)\n    tn = tf.reduce_sum(tf.cast(tf.equal((2.0*ytrue + ypred), tf.constant(0.0)), tf.float32), axis=1)\n    \n    acc = (tp+tn) / (tp+fp+fn+tn+epsilon)  \n    \n    return acc","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:01:19.474476Z","iopub.execute_input":"2021-10-19T18:01:19.475183Z","iopub.status.idle":"2021-10-19T18:01:19.486309Z","shell.execute_reply.started":"2021-10-19T18:01:19.475148Z","shell.execute_reply":"2021-10-19T18:01:19.485559Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# creating a function to build a sequential model\n\ndef build_model():\n    base_model = VGG19(include_top=False, weights='imagenet', input_shape=(128, 128, 3))\n    model = Sequential()\n    model.add(BatchNormalization(input_shape=(128, 128, 3)))\n    model.add(base_model)\n    model.add(Flatten())\n    model.add(Dense(17, activation='sigmoid'))\n    opt = Adam(lr=1e-4)\n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[multi_label_acc, fbeta])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:01:19.487588Z","iopub.execute_input":"2021-10-19T18:01:19.488069Z","iopub.status.idle":"2021-10-19T18:01:19.496656Z","shell.execute_reply.started":"2021-10-19T18:01:19.487923Z","shell.execute_reply":"2021-10-19T18:01:19.495773Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# initializing callbacks\nearly_stopping = EarlyStopping(monitor='val_fbeta', patience=10, mode='max', verbose=1)\nreduced_lr = ReduceLROnPlateau(monitor='val_fbeta', patience=3, cool_down=2, mode='max')\nsave_best_check_point = ModelCheckpoint(filepath='best_model.hdf5', monitor='val_fbeta', \\\n                                        mode='max', save_best_only=True, save_weights_only=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:01:19.498138Z","iopub.execute_input":"2021-10-19T18:01:19.498486Z","iopub.status.idle":"2021-10-19T18:01:19.509037Z","shell.execute_reply.started":"2021-10-19T18:01:19.498453Z","shell.execute_reply":"2021-10-19T18:01:19.508343Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# initializing an image data generator object with a validation split of 80:20\ntrain_image_gen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=180, horizontal_flip=True, \\\n                                            vertical_flip=True, validation_split=0.2)\n\n# generating the 80% training image data\ntrain_gen = train_image_gen.flow_from_dataframe(dataframe=train_df, \\\n        directory='../input/train-jpg/train-jpg/', x_col='image_name', y_col=y_col, \\\n       target_size=(128, 128), class_mode='raw', seed=0, batch_size=128, subset='training')\n\n# generating the 20% validation image data\nval_gen = train_image_gen.flow_from_dataframe(dataframe=train_df, \\\n        directory='../input/train-jpg/train-jpg/', x_col='image_name', y_col=y_col, \\\n       target_size=(128, 128), class_mode='raw', seed=0, batch_size=128, subset='validation')","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:01:19.510079Z","iopub.execute_input":"2021-10-19T18:01:19.510383Z","iopub.status.idle":"2021-10-19T18:01:43.179098Z","shell.execute_reply.started":"2021-10-19T18:01:19.510351Z","shell.execute_reply":"2021-10-19T18:01:43.178333Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# setting step size for training and validation image data\nstep_train_size = int(np.ceil(train_gen.samples / train_gen.batch_size))\nstep_val_size = int(np.ceil(val_gen.samples / train_gen.batch_size))","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:01:43.180179Z","iopub.execute_input":"2021-10-19T18:01:43.180739Z","iopub.status.idle":"2021-10-19T18:01:43.186180Z","shell.execute_reply.started":"2021-10-19T18:01:43.180693Z","shell.execute_reply":"2021-10-19T18:01:43.184967Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:02:20.600994Z","iopub.execute_input":"2021-10-19T18:02:20.601551Z","iopub.status.idle":"2021-10-19T18:02:20.608014Z","shell.execute_reply.started":"2021-10-19T18:02:20.601512Z","shell.execute_reply":"2021-10-19T18:02:20.605030Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:03:27.037813Z","iopub.execute_input":"2021-10-19T18:03:27.038350Z","iopub.status.idle":"2021-10-19T18:04:13.224112Z","shell.execute_reply.started":"2021-10-19T18:03:27.038312Z","shell.execute_reply":"2021-10-19T18:04:13.223405Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### building a sequential model for training","metadata":{}},{"cell_type":"code","source":"train_model = build_model() \n\n# fitting the model\ntrain_model.fit(x=train_gen, steps_per_epoch=step_train_size, validation_data=val_gen, validation_steps=step_val_size,\n         epochs=30, callbacks=[early_stopping, reduced_lr, save_best_check_point], )","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:04:25.865375Z","iopub.execute_input":"2021-10-19T18:04:25.865657Z","iopub.status.idle":"2021-10-19T20:20:14.770235Z","shell.execute_reply.started":"2021-10-19T18:04:25.865624Z","shell.execute_reply":"2021-10-19T20:20:14.769523Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# saving model to bin \nimport pickle\npickle.dump(train_model, open('final_model.bin', \"wb\"))","metadata":{"execution":{"iopub.status.busy":"2021-10-19T20:20:46.684551Z","iopub.execute_input":"2021-10-19T20:20:46.685093Z","iopub.status.idle":"2021-10-19T20:20:46.865502Z","shell.execute_reply.started":"2021-10-19T20:20:46.685058Z","shell.execute_reply":"2021-10-19T20:20:46.864633Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"filename = 'finalized_model.sav'\npickle.dump(train_model, open(filename, 'wb'))","metadata":{"execution":{"iopub.status.busy":"2021-10-19T20:26:26.241766Z","iopub.execute_input":"2021-10-19T20:26:26.242262Z","iopub.status.idle":"2021-10-19T20:26:26.409677Z","shell.execute_reply.started":"2021-10-19T20:26:26.242223Z","shell.execute_reply":"2021-10-19T20:26:26.407967Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# loading pickle model\nwith open('final_model.bin', 'rb') as f:\n    train_model = pickle.load(f)\n    f.close()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading pickle model\n# with open('final_model.bin', 'rb') as f:\n#     train_model = pickle.load(f)\n#     f.close()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T18:02:04.495561Z","iopub.status.idle":"2021-10-19T18:02:04.496180Z","shell.execute_reply.started":"2021-10-19T18:02:04.495960Z","shell.execute_reply":"2021-10-19T18:02:04.495982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### building a sequential model for testing","metadata":{}},{"cell_type":"code","source":"def test_data(df, rows_no, save=False):\n    test_model = build_model() \n    #loading in the weights of the trained model\n    test_model.load_weights('best_model.hdf5')\n    \n    # adding .jpg extension to 'image_name' col\n    df['image_name'] = df['image_name'].apply(lambda x: '{}.jpg'.format(x))\n\n    # selecting the first 40669 images from df\n#     test_df = df.iloc[:rows_no]['image_name'].reset_index().drop('index', axis=1)\n    \n    # selecting the remaining images from df\n    test_df = df.iloc[rows_no:]['image_name'].reset_index().drop('index', axis=1)\n\n    # initializing an image data generator object \n    test_image_gen = tf.keras.preprocessing.image.ImageDataGenerator()\n    \n#     # generating the image data \n#     test_gen = test_image_gen.flow_from_dataframe(dataframe=test_df, \\\n#             directory='../input/test-jpg/test-jpg/', x_col='image_name', y_col=None, \\\n#             batch_size=128, shuffle=False, class_mode=None, target_size=(128, 128))\n    \n    ## generating the image data for test- additional \n    test_gen = test_image_gen.flow_from_dataframe(dataframe=test_df, \\\n            directory='../input/test-jpg-additional/test-jpg-additional/', x_col='image_name', y_col=None, \\\n            batch_size=128, shuffle=False, class_mode=None, target_size=(128, 128))\n\n\n    # setting the step size \n    step_test_size = int(np.ceil(test_gen.samples / test_gen.batch_size))\n    \n    # reseting the generator to be sure of avoiding shuffling\n    test_gen.reset() \n    \n     # predicts the images in the df \n    pred = test_model.predict(test_gen, steps=step_test_size, verbose=1)\n    \n    # storing the filenames (images names) \n    test_file_names = test_gen.filenames \n        \n    # converting the predictions to tag names\n    pred_tags = pd.DataFrame(pred)\n    pred_tags = pred_tags.apply(lambda x: ' '.join(np.array(label_list)[x > 0.2]), axis=1)\n\n    # converting the predictions to a dataframe\n    result = pd.DataFrame({'image_name': test_file_names, 'tags': pred_tags})\n    \n    \n    return result\n","metadata":{"execution":{"iopub.status.busy":"2021-10-19T20:27:49.876321Z","iopub.execute_input":"2021-10-19T20:27:49.876638Z","iopub.status.idle":"2021-10-19T20:27:49.886834Z","shell.execute_reply.started":"2021-10-19T20:27:49.876581Z","shell.execute_reply":"2021-10-19T20:27:49.886115Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"### NOTE: The first 40669 datasets in submission_sample have their image data in test-jpg, \n### while the remaining datasets in submission_sample have their image data in test-jpg-additional","metadata":{}},{"cell_type":"code","source":"# predicting for submission_sample dataframe\nsample_df = pd.read_csv('../input/planet-understanding-the-amazon-from-space/sample_submission_v2.csv/sample_submission_v2.csv')\ntest_sample_1 = test_data(sample_df, 40669, True)\ntest_sample_1.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T20:21:05.225498Z","iopub.execute_input":"2021-10-19T20:21:05.226079Z","iopub.status.idle":"2021-10-19T20:26:26.240166Z","shell.execute_reply.started":"2021-10-19T20:21:05.226042Z","shell.execute_reply":"2021-10-19T20:26:26.239448Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# predicting for submission_sample dataframe\nsample_df = pd.read_csv('../input/planet-understanding-the-amazon-from-space/sample_submission_v2.csv/sample_submission_v2.csv')\ntest_sample_2 = test_data(sample_df, 40669, True)\ntest_sample_2.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T20:28:11.555281Z","iopub.execute_input":"2021-10-19T20:28:11.555529Z","iopub.status.idle":"2021-10-19T20:31:13.573755Z","shell.execute_reply.started":"2021-10-19T20:28:11.555501Z","shell.execute_reply":"2021-10-19T20:31:13.572983Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# concatenate the predictions of the test.jpg and test-additional.jpg into a single dataframe  \nfinal_result = pd.concat([test_sample_1, test_sample_2]) \n\n# reseting the index of the dataframe so it matches that of sample submission datafarme\nfinal_result = final_result.reset_index().drop('index', axis=1) \n\nfinal_result.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T20:31:19.998943Z","iopub.execute_input":"2021-10-19T20:31:19.999213Z","iopub.status.idle":"2021-10-19T20:31:20.018586Z","shell.execute_reply.started":"2021-10-19T20:31:19.999178Z","shell.execute_reply":"2021-10-19T20:31:20.017546Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"### saving the predictions","metadata":{}},{"cell_type":"code","source":"# removing the .jpg extension from 'image_name' column\nfinal_result['image_name'] = final_result['image_name'].apply(lambda x: x[:-4])\nfinal_result.to_csv('first_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T20:31:56.958119Z","iopub.execute_input":"2021-10-19T20:31:56.958745Z","iopub.status.idle":"2021-10-19T20:31:57.145294Z","shell.execute_reply.started":"2021-10-19T20:31:56.958703Z","shell.execute_reply":"2021-10-19T20:31:57.144567Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}